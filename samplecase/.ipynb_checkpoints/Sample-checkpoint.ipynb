{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657d47be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4f894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ac254",
   "metadata": {},
   "source": [
    "<b>DATA SET:</b>\n",
    "\n",
    "<b>Books</b> – first are about books which contain all the information related to books like an author, title, publication year, etc.</br>\n",
    "<b>Users</b> – The second file contains registered user’s information like user id, location.</br>\n",
    "<b>Ratings</b> –  Ratings contain information like which user has given how much rating to which book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8bb0e",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3363abd",
   "metadata": {},
   "source": [
    "let us start while importing libraries and load datasets. while loading the file we have some problems like.\n",
    "\n",
    " The values in the CSV file are separated by semicolons, not by a comma.\n",
    "There are some lines which not work like we cannot import it with pandas and It throws an error because python is Interpreted language.\n",
    "Encoding of a file is in Latin\n",
    "So while loading data we have to handle these exceptions and after running the below code you will get some warning and it will show which lines have an error that we have skipped while loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69c3c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roethelchristine/final/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3457: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "/Users/roethelchristine/final/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3457: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv(\"BX-Books.csv\", sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
    "users = pd.read_csv(\"BX-Users.csv\", sep=';', encoding=\"latin-1\", error_bad_lines=False)\n",
    "ratings = pd.read_csv(\"BX-Book-Ratings.csv\", sep=';', encoding=\"latin-1\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806cde7",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88336318",
   "metadata": {},
   "source": [
    "Now in the books file, we have some extra columns which are not required for our task like image URLs. And we will rename the columns of each file as the name of the column contains space, and uppercase letters so we will correct as to make it easy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dfbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher']]\n",
    "books.rename(columns = {'Book-Title':'title', 'Book-Author':'author', 'Year-Of-Publication':'year', 'Publisher':'publisher'}, inplace=True)\n",
    "users.rename(columns = {'User-ID':'user_id', 'Location':'location', 'Age':'age'}, inplace=True)\n",
    "ratings.rename(columns = {'User-ID':'user_id', 'Book-Rating':'rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56b8bbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                              title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "                 author  year                   publisher  \n",
       "0    Mark P. O. Morford  2002     Oxford University Press  \n",
       "1  Richard Bruce Wright  2001       HarperFlamingo Canada  \n",
       "2          Carlo D'Este  1991             HarperPerennial  \n",
       "3      Gina Bari Kolata  1999        Farrar Straus Giroux  \n",
       "4       E. J. W. Barber  1999  W. W. Norton &amp; Company  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9fceac",
   "metadata": {},
   "source": [
    "The dataset is reliable and can consider as a large dataset. we have 271360 books data and total registered users on the website are approximately 278000 and they have given near about 11 lakh rating. hence we can say that the dataset we have is nice and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe370c7",
   "metadata": {},
   "source": [
    "Approach to a problem statement:\n",
    "\n",
    "We do not want to find a similarity between users or books. we want to do that If there is user A who has read and liked x and y books, And user B has also liked this two books and now user A has read and liked some z book which is not read by B so we have to recommend z book to user B. This is what collaborative filtering is.\n",
    "\n",
    "So this is achieved using Matrix Factorization, we will create one matrix where columns will be users and indexes will be books and value will be rating. Like we have to create a Pivot table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae1586",
   "metadata": {},
   "source": [
    "A big flaw with a problem statement in the dataset:\n",
    "\n",
    "If we take all the books and all the users for modeling, Don’t you think will it create a problem? So what we have to do is we have to decrease the number of users and books because we cannot consider a user who has only registered on the website or has only read one or two books. On such a user, we cannot rely to recommend books to others because we have to extract knowledge from data. So what we will limit this number and we will take a user who has rated at least 200 books and also we will limit books and we will take only those books which have received at least 50 ratings from a user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c97ef8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724c8e0",
   "metadata": {},
   "source": [
    "So let’s get with analysis and prepare the dataset as we discussed for modeling. let us see how many users have given ratings and extract those users who have given more than 200 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "757e4bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676     13602\n",
       "198711     7550\n",
       "153662     6109\n",
       "98391      5891\n",
       "35859      5850\n",
       "          ...  \n",
       "116180        1\n",
       "116166        1\n",
       "116154        1\n",
       "116137        1\n",
       "276723        1\n",
       "Name: user_id, Length: 105283, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdf183",
   "metadata": {},
   "source": [
    "### Step 1. Extract users and ratings of more than 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efdfdb6",
   "metadata": {},
   "source": [
    "when you run the above code we can see only 105283 peoples have given a rating among 278000. Now we will extract the user ids who have given more than 200 ratings and when we will have user ids we will extract the ratings of only this user id from the rating dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec19a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899,)\n"
     ]
    }
   ],
   "source": [
    "x = ratings['user_id'].value_counts() > 200\n",
    "y = x[x].index  #user_ids\n",
    "print(y.shape)\n",
    "ratings = ratings[ratings['user_id'].isin(y)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dbdc13",
   "metadata": {},
   "source": [
    "### Step 2. Merge ratings with books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4935296",
   "metadata": {},
   "source": [
    "So 900 users are there who have given 5.2 lakh rating and this we want. Now we will merge ratings with books on basis of ISBN so that we will get the rating of each user on each book id and the user who has not rated that book id the value will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03dff245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277427</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3363</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11676</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>6</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12538</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>10</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13552</td>\n",
       "      <td>002542730X</td>\n",
       "      <td>0</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        ISBN  rating  \\\n",
       "0   277427  002542730X      10   \n",
       "1     3363  002542730X       0   \n",
       "2    11676  002542730X       6   \n",
       "3    12538  002542730X      10   \n",
       "4    13552  002542730X       0   \n",
       "\n",
       "                                               title             author  year  \\\n",
       "0  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "1  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "2  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "3  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "4  Politically Correct Bedtime Stories: Modern Ta...  James Finn Garner  1994   \n",
       "\n",
       "                   publisher  \n",
       "0  John Wiley &amp; Sons Inc  \n",
       "1  John Wiley &amp; Sons Inc  \n",
       "2  John Wiley &amp; Sons Inc  \n",
       "3  John Wiley &amp; Sons Inc  \n",
       "4  John Wiley &amp; Sons Inc  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_with_books = ratings.merge(books, on='ISBN')\n",
    "rating_with_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec9779c",
   "metadata": {},
   "source": [
    "### Step 3. Extract books that have received more than 50 ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49cbff0",
   "metadata": {},
   "source": [
    "Now dataframe size has decreased and we have 4.8 lakh because when we merge the dataframe, all the book id-data we were not having. Now we will count the rating of each book so we will group data based on title and aggregate based on rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daa69aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_rating = rating_with_books.groupby('title')['rating'].count().reset_index()\n",
    "number_rating.rename(columns= {'rating':'number_of_ratings'}, inplace=True)\n",
    "final_rating = rating_with_books.merge(number_rating, on='title')\n",
    "final_rating.shape\n",
    "final_rating = final_rating[final_rating['number_of_ratings'] >= 50]\n",
    "final_rating.drop_duplicates(['user_id','title'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64256901",
   "metadata": {},
   "source": [
    "we have to drop duplicate values because if the same user has rated the same book multiple times so it will create a problem. Finally, we have a dataset with that user who has rated more than 200 books and books that received more than 50 ratings. the shape of the final dataframe is 59850 rows and 8 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af86835",
   "metadata": {},
   "source": [
    "### Step 4. Create Pivot Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689aedd",
   "metadata": {},
   "source": [
    "As we discussed above we will create a pivot table where columns will be user ids, the index will be book title and the value is ratings. And the user id who has not rated any book will have value as NAN so impute it with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8febce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_pivot = final_rating.pivot_table(columns='user_id', index='title', values=\"rating\")\n",
    "book_pivot.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e384a2",
   "metadata": {},
   "source": [
    "We can see the more than 11 users have removed out because their ratings were on those books which do not receive more than 50 ratings so they are moved out of the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf989037",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53059b82",
   "metadata": {},
   "source": [
    "We have prepared our dataset for modeling. we will use the nearest neighbors algorithm which is the same as K nearest which is used for clustering based on euclidian distance.\n",
    "\n",
    "But here in the pivot table, we have lots of zero values and on clustering, this computing power will increase to calculate the distance of zero values so we will convert the pivot table to the sparse matrix and then feed it to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a36c2",
   "metadata": {},
   "source": [
    "<b>(pip install scipy or brew install scipy if not already installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8683c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f321b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_sparse = csr_matrix(book_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044ebe13",
   "metadata": {},
   "source": [
    "Now we will train the nearest neighbors algorithm. here we need to specify an algorithm which is brute means find the distance of every point to every other point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78725a8",
   "metadata": {},
   "source": [
    "<b> (pip install scikit-learn if not already installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "699b5576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "model = NearestNeighbors(algorithm='brute')\n",
    "model.fit(book_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a257d",
   "metadata": {},
   "source": [
    "Let’s make a prediction and see whether it is suggesting books or not. we will find the nearest neighbors to the input book id and after that, we will print the top 5 books which are closer to those books. It will provide us distance and book id at that distance. let us pass harry potter which is at 237 indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3138cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, suggestions = model.kneighbors(book_pivot.iloc[23, :].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdf25ee",
   "metadata": {},
   "source": [
    "let us print all the suggested books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661e6a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A Thin Dark Line (Mysteries &amp; Horror)', 'Exclusive',\n",
      "       'Long After Midnight', 'No Safe Place',\n",
      "       'Deck the Halls (Holiday Classics)'],\n",
      "      dtype='object', name='title')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(suggestions)):\n",
    "  print(book_pivot.index[suggestions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958cf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
